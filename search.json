[{"path":"/CODE_OF_CONDUCT.html","id":null,"dir":"","previous_headings":"","what":"Contributor Code of Conduct","title":"Contributor Code of Conduct","text":"contributors maintainers project, pledge respect people contribute reporting issues, posting feature requests, updating documentation, submitting pull requests patches, activities. committed making participation project harassment-free experience everyone, regardless level experience, gender, gender identity expression, sexual orientation, disability, personal appearance, body size, race, ethnicity, age, religion. Examples unacceptable behavior participants include use sexual language imagery, derogatory comments personal attacks, trolling, public private harassment, insults, unprofessional conduct. Project maintainers right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct. Project maintainers follow Code Conduct may removed project team. Instances abusive, harassing, otherwise unacceptable behavior may reported opening issue contacting one project maintainers. Code Conduct adapted Contributor Covenant (http://contributor-covenant.org), version 1.0.0, available http://contributor-covenant.org/version/1/0/0/","code":""},{"path":[]},{"path":[]},{"path":"/CONTRIBUTING.html","id":"bugs","dir":"","previous_headings":"","what":"Bugs?","title":"CONTRIBUTING","text":"Submit issue Issues page sure include R session information reproducible example (repex).","code":""},{"path":[]},{"path":"/CONTRIBUTING.html","id":"broad-overview-of-contributing-workflow","dir":"","previous_headings":"Code contributions","what":"Broad overview of contributing workflow","title":"CONTRIBUTING","text":"Fork repository GitHub account Clone version account machine account, e.g,. git clone https://github.com/XXX/XXX.git Make sure track progress upstream (.e., version XXX XXX/XXX) git remote add upstream https://github.com/XXX/XXX.git. making changes make sure pull changes upstream either git fetch upstream merge later git pull upstream fetch merge one step Make changes (bonus points making changes new feature branch) Please write test(s) changes affect code just docs (see Tests ) Push account Submit pull request home base XXX/XXX","code":""},{"path":"/CONTRIBUTING.html","id":"tests","dir":"","previous_headings":"Code contributions","what":"Tests","title":"CONTRIBUTING","text":"add tests, go folder tests/testthat/. Tests generally organized individual files exported function package (, listed export NAMESPACE file). adding new exported function, add new test file. changing existing function, work tests file function, unless doesn’t tests, case make new test file. book R packages book provides chapter testing general. consult first aren’t familiar testing R. easiest set run tests within R session: test individual test file run tests running tests skip_on_cran() , set Sys.setenv(NOT_CRAN = \"true\") prior running tests.","code":"library(devtools) library(testthat) # loads the package load_all() test_file(\"tests/testthat/test-foobar.R\") devtools::test()"},{"path":"/CONTRIBUTING.html","id":"making-changes","dir":"","previous_headings":"Code contributions","what":"Making changes","title":"CONTRIBUTING","text":"addition changing code, make sure update documentation applicable. R packages book book chapter documentation read aren’t familiar. code documentation changed, update documentation running either devtools::document() roxygen2::roxygenise(). Make sure change packages even functions within packages imported, likely add package Imports DESCRIPTION file. conservative adding new dependencies.","code":""},{"path":"/CONTRIBUTING.html","id":"style","dir":"","previous_headings":"Code contributions","what":"Style","title":"CONTRIBUTING","text":"Make sure code, documentation, comments 80 characters width; Use https://style.tidyverse.org/.","code":""},{"path":[]},{"path":"/articles/get_started.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Get started with SAVM","text":"vignette provides overview workflow offered Submerged Aquatic Vegetation Model (SAVM) R package. package allows users import spatial tabular data related SAV presence habitat conditions aquatic ecosystems. presented vignette provide overview functionalities built package presents workflow user input model predictions.","code":""},{"path":[]},{"path":"/articles/get_started.html","id":"r-as-a-gis","dir":"Articles","previous_headings":"User workflow","what":"R as a GIS","title":"Get started with SAVM","text":"use SAVM, basic knowledge using R work spatial objects. several packages turn R powerful Geospatial Information System (GIS). One popular sf, can read wide variety spatial file formats, including ESRI shapefiles. Assuming following shapefile files: st_read(lake_erie_land/LkErie_Land_fromGLAF_Water_WGS_Feb2020.shx) used read shapefile sf object used spatial operations R. instance, shapefile can plot follows:  package SAVM includes util function invert polygon.  Using sf capacities, file can exported various format, instance GeoPackage: Note sf focuses vector files, read manipulate raster file use package stars works seamlessly sf.","code":"lake_erie_land ├── LkErie_Land_fromGLAF_Water_WGS_Feb2020.cpg ├── LkErie_Land_fromGLAF_Water_WGS_Feb2020.dbf ├── LkErie_Land_fromGLAF_Water_WGS_Feb2020.prj ├── LkErie_Land_fromGLAF_Water_WGS_Feb2020.sbn ├── LkErie_Land_fromGLAF_Water_WGS_Feb2020.sbx ├── LkErie_Land_fromGLAF_Water_WGS_Feb2020.shp ├── LkErie_Land_fromGLAF_Water_WGS_Feb2020.shp.xml └── LkErie_Land_fromGLAF_Water_WGS_Feb2020.shx erie_land <- st_read(\"lake_erie_land/LkErie_Land_fromGLAF_Water_WGS_Feb2020.shx\") plot(erie_land) #> Reading layer `LkErie_Land_fromGLAF_Water_WGS_Feb2020' from data source  #>   `/home/runner/work/_temp/Library/SAVM/example/lake_erie_land/LkErie_Land_fromGLAF_Water_WGS_Feb2020.shx'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 1 feature and 8 fields #> Geometry type: MULTIPOLYGON #> Dimension:     XYZ #> Bounding box:  xmin: -83.58067 ymin: 41.30372 xmax: -78.72656 ymax: 42.99789 #> z_range:       zmin: 0 zmax: 0 #> Geodetic CRS:  WGS 84 erie_lake  <- erie_land |>   invert_polygon() #> although coordinates are longitude/latitude, st_difference assumes that they #> are planar #> Warning: attribute variables are assumed to be spatially constant throughout #> all geometries    erie_lake |>   st_geometry() |>   plot(col = 1) erie_lake |> sf::st_write(\"lake_erie.gpkg\")"},{"path":"/articles/get_started.html","id":"reading-file","dir":"Articles","previous_headings":"User workflow","what":"Reading file","title":"Get started with SAVM","text":"Now consider zone near Buffalo Lake Erie. Note data required included package SAVM. first load geopackage Lake Erie. load shapefile area interest stored GeoJSON file. Note area (points) interest, use read_sav() returns object class sav_data. Note corresponfing grid can visualized using preview_grid() function.  now load depth data. Note spatial projections: SAVM package works spatial coordinates meters WGS 84 / UTM zone 17N (epsg:32617) projection default option since originally developped use Great Lakes (WGS 84 / UTM zone 18N (epsg:32618) also option). viable options North American context NAD83 / UTM zone 17N (epsg:26917) NAD83(CSRS) / UTM zone 17N (egsg::2958).","code":"# Lake Erie boundaries polygon (reading from SAVM internal files) le_bound <- system.file(\"example\", \"lake_erie.gpkg\", package = \"SAVM\") |>   sf::st_read() |>   sf::st_transform(crs = 3857) #> Reading layer `lake_erie' from data source  #>   `/home/runner/work/_temp/Library/SAVM/example/lake_erie.gpkg'  #>   using driver `GPKG' #> Simple feature collection with 1 feature and 1 field #> Geometry type: MULTIPOLYGON #> Dimension:     XYZ #> Bounding box:  xmin: -83.47975 ymin: 41.38081 xmax: -78.85269 ymax: 42.94512 #> z_range:       zmin: 0 zmax: 0 #> Geodetic CRS:  WGS 84 # Lake Erie study zone: read study_zone <- system.file(\"example\", \"study_zone.geojson\", package = \"SAVM\") |>   read_sav(spacing = 2000) #> ℹ Determining file type and processing: /home/runner/work/_temp/Library/SAVM/example/study_zone.geojson #> ℹ spatial file detected #> ℹ Transforming spatial data. #> ✔ Grid of 46 points successfully generated from AOI. preview_grid(study_zone) # Depth (reading with stars) study_depth <- stars::read_stars(system.file(\"example\", \"le_bathy.tiff\", package = \"SAVM\"))"},{"path":[]},{"path":"/articles/get_started.html","id":"compute-fetch","dir":"Articles","previous_headings":"User workflow > Compute fetch and extract depth","what":"Compute fetch","title":"Get started with SAVM","text":"compute wind fetch (kilometers), called compute_fetch(). default, maximum distance set 15 km (see argument max_dist) default number bearings 16 (see argument n_bearings). fetch list two elements, mean_fetch, sf object summarized computations transect_lines, sf object includes transect lines. sf objects, elements can easily exported, instance, following code writes fetch$mean_fetch shapefile:","code":"fetch <- compute_fetch(study_zone$points, le_bound) #> ℹ `points` and `polygon` have different CRS, transforming #> `points` to match `polygon` CRS. #> ℹ Creating fetch lines #> ℹ Cropping fetch lines fetch #> $mean_fetch #> Simple feature collection with 46 features and 3 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: -8802296 ymin: 5273114 xmax: -8780591 ymax: 5292232 #> Projected CRS: WGS 84 / Pseudo-Mercator #> First 10 features: #>    id_point  fetch_km weighted_fetch_km                 geometry #> 1         1 12.006874         12.006874 POINT (-8794389 5273245) #> 2         2 11.297231         11.297231 POINT (-8791670 5273180) #> 3         3  9.807624          9.807624 POINT (-8788952 5273114) #> 4         4 13.778605         13.778605 POINT (-8797044 5276038) #> 5         5 13.111403         13.111403 POINT (-8794324 5275974) #> 6         6 12.380803         12.380803 POINT (-8791605 5275909) #> 7         7 11.437303         11.437303 POINT (-8788886 5275843) #> 8         8 10.087690         10.087690 POINT (-8786166 5275776) #> 9         9 14.375036         14.375036 POINT (-8799700 5278832) #> 10       10 14.236961         14.236961 POINT (-8796980 5278768) #>  #> $transect_lines #> Simple feature collection with 736 features and 6 fields #> Geometry type: LINESTRING #> Dimension:     XYZ #> Bounding box:  xmin: -8817296 ymin: 5262180 xmax: -8777847 ymax: 5297596 #> z_range:       zmin: 0 zmax: 0 #> Projected CRS: WGS 84 / Pseudo-Mercator #> # A tibble: 736 × 7 #> # Groups:   id_point [46] #>    id_point direction weight OBJECTID_1                                 geometry #>  *    <int>     <dbl>  <dbl>      <dbl>                         <LINESTRING [m]> #>  1        1       0        1          0 Z (-8794389 5273245 0, -8784003 5273245… #>  2        1      22.5      1          0 Z (-8794389 5273245 0, -8780530 5278985… #>  3        1      45        1          0 Z (-8794389 5273245 0, -8783782 5283852… #>  4        1      67.5      1          0 Z (-8794389 5273245 0, -8788648 5287103… #>  5        1      90        1          0 Z (-8794389 5273245 0, -8794389 5288245… #>  6        1     112.       1          0 Z (-8800129 5287103 0, -8794389 5273245… #>  7        1     135        1          0 Z (-8804995 5283852 0, -8794389 5273245… #>  8        1     158.       1          0 Z (-8808247 5278985 0, -8794389 5273245… #>  9        1     180        1          0 Z (-8809389 5273245 0, -8794389 5273245… #> 10        1     202.       1          0 Z (-8808247 5267505 0, -8794389 5273245… #> # ℹ 726 more rows #> # ℹ 2 more variables: transect_length [m], rank <int> fetch$mean_fetch  |> sf::st_write(\"fetch.shp\")"},{"path":"/articles/get_started.html","id":"extract-depth","dir":"Articles","previous_headings":"User workflow > Compute fetch and extract depth","what":"Extract depth","title":"Get started with SAVM","text":"extract depth data raster file study points, use st_extract() package stars. Note points raster must use projection. return sf object ad le_bathy.tiff contain depth values.","code":"depth <- st_extract(   study_depth,    study_zone$points |>     sf::st_transform(crs = sf::st_crs(study_depth)) ) depth #> Simple feature collection with 46 features and 1 field #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 1369010 ymin: 2317621 xmax: 1385038 ymax: 2332455 #> Projected CRS: USA_Contiguous_Albers_Equal_Area_Conic_USGS_version #> First 10 features: #>    le_bathy.tiff                geometry #> 1      13.387704 POINT (1376150 2317621) #> 2      12.846224 POINT (1378114 2317928) #> 3       9.828735 POINT (1380079 2318235) #> 4      14.185731 POINT (1373874 2319302) #> 5      14.000000 POINT (1375838 2319609) #> 6      14.000000 POINT (1377803 2319916) #> 7      12.106031 POINT (1379767 2320222) #> 8       9.033901 POINT (1381732 2320529) #> 9      17.807201 POINT (1371598 2320983) #> 10     17.075397 POINT (1373562 2321290)"},{"path":"/articles/get_started.html","id":"model","dir":"Articles","previous_headings":"User workflow","what":"Model","title":"Get started with SAVM","text":"depth fetch, create sf object contains predictor values points. can generate predictions using sav_model(sp_dat). default, function uses column names input data identify relevant variables. column names recognized, can manually specify using depth fetch parameters. Even without additional columns, model return columns containing post hoc results. SAV cover, presence-absence predictions available, cover_post_hoc column contain cover_pred values set 0 absence predicted. three additionnal limitaions can used posthoc treatement. secchi parameter contain Secchi depth values used compute Vmax following equation Chambers Kalff (1985). depth also provided, compared Vmax: depth exceeds Vmax, cover presence-absence set 0. substrate limitation parameters binary variables can used set cover presence-absence 0 based external knowledge site-specific constraints. used example random Secchi depth values: Note res_secchi sf object can therefore exported shapefile:","code":"sp_dat <- fetch$mean_fetch sp_dat$depth_m <- depth$le_bathy.tiff # get input res <- sav_model(sp_dat) #> ℹ Looking for depth and fetch in column names. #> ℹ Found Fetch and Depth in column names. #> ℹ Using cover and pa with depth+fetch res #> Simple feature collection with 46 features and 6 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: -8802296 ymin: 5273114 xmax: -8780591 ymax: 5292232 #> Projected CRS: WGS 84 / Pseudo-Mercator #> First 10 features: #>     fetch_km   depth_m pa_pred cover_pred pa_post_hoc cover_post_hoc #> 1  12.006874 13.387704       0   13.59122           0        0.00000 #> 2  11.297231 12.846224       0   13.68788           0        0.00000 #> 3   9.807624  9.828735       1   32.93014           1       32.93014 #> 4  13.778605 14.185731       0   13.29559           0        0.00000 #> 5  13.111403 14.000000       0   13.12659           0        0.00000 #> 6  12.380803 14.000000       0   13.28681           0        0.00000 #> 7  11.437303 12.106031       0   13.68788           0        0.00000 #> 8  10.087690  9.033901       1   23.73997           1       23.73997 #> 9  14.375036 17.807201       0   13.22826           0        0.00000 #> 10 14.236961 17.075397       0   13.22826           0        0.00000 #>                    geometry #> 1  POINT (-8794389 5273245) #> 2  POINT (-8791670 5273180) #> 3  POINT (-8788952 5273114) #> 4  POINT (-8797044 5276038) #> 5  POINT (-8794324 5275974) #> 6  POINT (-8791605 5275909) #> 7  POINT (-8788886 5275843) #> 8  POINT (-8786166 5275776) #> 9  POINT (-8799700 5278832) #> 10 POINT (-8796980 5278768) res_secchi <- sav_model(   cbind(sp_dat, secchi = runif(nrow(sp_dat), 4, 12))   ) #> ℹ Looking for depth and fetch in column names. #> ℹ Found Fetch and Depth in column names. #> ℹ Using cover and pa with depth+fetch res_secchi #> Simple feature collection with 46 features and 9 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: -8802296 ymin: 5273114 xmax: -8780591 ymax: 5292232 #> Projected CRS: WGS 84 / Pseudo-Mercator #> First 10 features: #>     fetch_km   depth_m    secchi limitation_secchi     vmax pa_pred cover_pred #> 1  12.006874 13.387704  4.646001             FALSE 11.37638       0   13.59122 #> 2  11.297231 12.846224 10.674664              TRUE 20.06387       0   13.68788 #> 3   9.807624  9.828735  8.806087              TRUE 17.83660       1   32.93014 #> 4  13.778605 14.185731  5.257668             FALSE 12.51309       0   13.29559 #> 5  13.111403 14.000000  4.059196             FALSE 10.19723       0   13.12659 #> 6  12.380803 14.000000  7.731148              TRUE 16.40406       0   13.28681 #> 7  11.437303 12.106031  7.982219              TRUE 16.75018       0   13.68788 #> 8  10.087690  9.033901  6.318138              TRUE 14.30167       1   23.73997 #> 9  14.375036 17.807201  9.863056              TRUE 19.13274       0   13.22826 #> 10 14.236961 17.075397 10.180172              TRUE 19.50271       0   13.22826 #>    pa_post_hoc cover_post_hoc                 geometry #> 1            0        0.00000 POINT (-8794389 5273245) #> 2            0        0.00000 POINT (-8791670 5273180) #> 3            1       32.93014 POINT (-8788952 5273114) #> 4            0        0.00000 POINT (-8797044 5276038) #> 5            0        0.00000 POINT (-8794324 5275974) #> 6            0        0.00000 POINT (-8791605 5275909) #> 7            0        0.00000 POINT (-8788886 5275843) #> 8            1       23.73997 POINT (-8786166 5275776) #> 9            0        0.00000 POINT (-8799700 5278832) #> 10           0        0.00000 POINT (-8796980 5278768) res_secchi |> sf::st_write(\"results.shp\")"},{"path":"/articles/get_started.html","id":"vizualize","dir":"Articles","previous_headings":"User workflow","what":"Vizualize","title":"Get started with SAVM","text":"package includes plotting helper functions. plot_sav_distribution(res) allows users visualize distribution SAV cover presence/absence across predictor bins. Alternatively, plot_sav_density(res) provides density-based visualization rather using binned values.   Note functions include option force use raw predictions without applying post hoc treatment.   Finally, function plot_sav_tmap() allows draw map leveraging package tmap (https://r-tmap.github.io/tmap/).","code":"# Visualize results plot_sav_distribution(res_secchi) plot_sav_density(res_secchi) plot_sav_distribution(res_secchi, post_hoc = FALSE) plot_sav_density(res_secchi, post_hoc = FALSE) study_zone$points <- cbind(study_zone$points, res) plot_sav_tmap(study_zone) plot_sav_tmap(study_zone, layers = \"cover\", interactive = FALSE)"},{"path":"/articles/get_started.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Get started with SAVM","text":"Croft-White, M.V., Tang, R., Gardner Costa, J., Doka, S.E., Midwood, J. D. 2022. Modelling submerged aquatic vegetation presence percent cover support development freshwater fish habitat management tool. Can. Tech. Rep. Fish. Aquat. Sci. 3497: vi + 30 p. Chambers, P.., Kalff, J. 1985. Depth Distribution Biomass Submerged aquatic macrophyte communities relation secchi depth. Can. J. Fish. Aquat. Sci. 42: 701–709","code":""},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Kevin Cazelles. Author, maintainer. David Beauchesne. Author. Paul Bozneck. Author.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Cazelles K, Beauchesne D, Bozneck P (2025). SAVM: Submerged aquatic vegetation model. R package version 0.0.1.9004, https://github.com/FishEcologyScience/SAVM.","code":"@Manual{,   title = {SAVM: Submerged aquatic vegetation model},   author = {Kevin Cazelles and David Beauchesne and Paul Bozneck},   year = {2025},   note = {R package version 0.0.1.9004},   url = {https://github.com/FishEcologyScience/SAVM}, }"},{"path":[]},{"path":"/index.html","id":"background","dir":"","previous_headings":"","what":"Background","title":"Submerged aquatic vegetation model","text":"Fisheries Oceans Canada (DFO) responsible management aquatic freshwater habitat Fish Fish Habitat Protection Program seeking tools can help decision support process. Fish Ecology Science Lab DFO developed general models predict presence cover submerged aquatic vegetation (SAV) Laurentian Great Lakes (Croft-White et al. 2022). SAV critical component fish habitat frequently affected -water works habitat improvement initiatives. Croft-White et al. (2022) outlines completed SAV model R-package web-application tool created utilized. DFO GLLFAS capacity create necessary R package requires services contractor advance works. key aspect package development ensuring tool development within DFO can follow similar methods tools can integrated , minimum, contain input outputs can moved among tools.","code":""},{"path":[]},{"path":"/index.html","id":"for-developers","dir":"","previous_headings":"Resources","what":"For developers","title":"Submerged aquatic vegetation model","text":"windfetch: https://github.com/blasee/windfetch; previously fetchR (https://cran.r-project.org/src/contrib/Archive/fetchR/fetchR_2.1-1.tar.gz) https://r-pkgs.org https://style.tidyverse.org/","code":""},{"path":"/index.html","id":"sav","dir":"","previous_headings":"Resources","what":"SAV","title":"Submerged aquatic vegetation model","text":"Croft-White, M.V., Tang, R., Gardner Costa, J., Doka, S.E., Midwood, J. D. 2022. Modelling submerged aquatic vegetation presence percent cover support development freshwater fish habitat management tool. Can. Tech. Rep. Fish. Aquat. Sci. 3497: vi + 30 p. Chambers, P.., Kalff, J. 1985. Depth Distribution Biomass Submerged aquatic macrophyte communities relation secchi depth. Can. J. Fish. Aquat. Sci. 42: 701–709","code":""},{"path":"/index.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Submerged aquatic vegetation model","text":"Please note project released Contributor Code Conduct. participating project agree abide terms.","code":""},{"path":"/reference/compute_fetch.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute wind fetch and wind weighted fetch — compute_fetch","title":"Compute wind fetch and wind weighted fetch — compute_fetch","text":"Compute wind fetch wind weighted fetch","code":""},{"path":"/reference/compute_fetch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute wind fetch and wind weighted fetch — compute_fetch","text":"","code":"compute_fetch(   points,   polygon,   max_dist = 15,   n_bearings = 16,   wind_weights = NULL,   crs = NULL )"},{"path":"/reference/compute_fetch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute wind fetch and wind weighted fetch — compute_fetch","text":"points sf Points representing locations fetch calculated. polygon sf Polygon defining land boundaries used compute fetch distances. max_dist numeric Maximum fetch distance kilometers. Fetch beyond distance capped. n_bearings integer Total number bearings fetch calculation (minimal number required 4, default 167). Ignored wind_weights provided. wind_weights data.frame data frame specifying directional weights wind exposure. Must contain two columns: direction (numeric, degrees) weight (numeric). Note weighting applies points. crs object Coordinate reference system (CRS) passed sf::st_crs(), used transform points polygon.","code":""},{"path":"/reference/compute_fetch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute wind fetch and wind weighted fetch — compute_fetch","text":"list two elements: mean_fetch: sf object 3 features: id_point: point identifier fetch_km: mean wind fetch based bearings. weighted_fetch_km: mean weighted wind fetch based bearings. transect_lines: sf object containing radial transect columns points following additional columns: id_point: point identifier direction: direction (degree) weight: wind weight transect_length: transect length meter computed using sf::st_length(). rank: transect ranks (lower rank higher length).","code":""},{"path":"/reference/compute_fetch.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute wind fetch and wind weighted fetch — compute_fetch","text":"Wind fetch unobstructed distance wind travels across body water reaching specific point. plays crucial role wave generation, longer fetch distances allow wind transfer energy water surface, leading larger waves. points points, n_bearings radial transects generated default. wind_weights specified, column direction, contains angles degrees, used instead generate transects. transects clipped polygon using sf::st_intersection(), lines connected points removed. length clipped transects computed using sf::st_length() ranked using rank(). resulting spatial object stored transect_lines element returned list used generate second element: mean_fetch included wind fetch averages. Ensure max_dist specified meters. error thrown spatial projection points polygon meter-based coordinate system.","code":""},{"path":"/reference/compute_fetch.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute wind fetch and wind weighted fetch — compute_fetch","text":"implementation leveraging  sf::st_buffer(), see https://github.com/blasee/windfetch. Croft-White, M.V., Tang, R., Gardner Costa, J., Doka, S.E., Midwood, J. D. 2022. Modelling submerged aquatic vegetation presence percent cover support development freshwater fish habitat management tool. Can. Tech. Rep. Fish. Aquat. Sci. 3497: vi + 30 p.","code":""},{"path":"/reference/compute_fetch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute wind fetch and wind weighted fetch — compute_fetch","text":"","code":"# \\donttest{ le_bound <- system.file(\"example\", \"lake_erie.gpkg\", package = \"SAVM\") |>     sf::st_read() #> Reading layer `lake_erie' from data source  #>   `/home/runner/work/_temp/Library/SAVM/example/lake_erie.gpkg'  #>   using driver `GPKG' #> Simple feature collection with 1 feature and 1 field #> Geometry type: MULTIPOLYGON #> Dimension:     XYZ #> Bounding box:  xmin: -83.47975 ymin: 41.38081 xmax: -78.85269 ymax: 42.94512 #> z_range:       zmin: 0 zmax: 0 #> Geodetic CRS:  WGS 84 le_pt <- system.file(\"example\", \"le_points.geojson\", package = \"SAVM\") |>     sf::st_read(quiet = TRUE) res <- compute_fetch(le_pt, le_bound, crs = 32617) #> ℹ Creating fetch lines #> ℹ Cropping fetch lines # use wind-weight res2 <- compute_fetch(     le_pt, le_bound,     max_dist = 20,     wind_weights = data.frame(         direction = seq(0, 360, by = 360 / 16)[-1],         weight = rep(c(0, 1), each = 8)     ),     crs = 32617 ) #> ℹ Using `wind_weights`, ignoring `n_bearings` #> ℹ Creating fetch lines #> ℹ Cropping fetch lines  # results res$mean_fetch #> Simple feature collection with 6 features and 3 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 299367.8 ymin: 4599578 xmax: 424951.8 ymax: 4682035 #> Projected CRS: WGS 84 / UTM zone 17N #>   id_point fetch_km weighted_fetch_km                 geometry #> 1        1 1.342992          1.342992 POINT (323487.6 4664158) #> 2        2 8.114764          8.114764 POINT (325611.7 4656173) #> 3        3 9.634700          9.634700 POINT (340150.6 4649137) #> 4        4 6.819028          6.819028 POINT (340372.5 4599578) #> 5        5 2.897416          2.897416 POINT (424951.8 4682035) #> 6        6 8.284419          8.284419 POINT (299367.8 4629965) res2$mean_fetch #> Simple feature collection with 6 features and 3 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 299367.8 ymin: 4599578 xmax: 424951.8 ymax: 4682035 #> Projected CRS: WGS 84 / UTM zone 17N #>   id_point  fetch_km weighted_fetch_km                 geometry #> 1        1  1.342992         0.7984408 POINT (323487.6 4664158) #> 2        2  9.677264         7.5772252 POINT (325611.7 4656173) #> 3        3 12.759700        10.0000000 POINT (340150.6 4649137) #> 4        4  8.069028         1.2275138 POINT (340372.5 4599578) #> 5        5  2.897416         1.4788449 POINT (424951.8 4682035) #> 6        6  9.846919         5.9544707 POINT (299367.8 4629965)  # visualizing fetch lines plot(le_bound |> sf::st_transform(crs = 32617) |> sf::st_geometry()) plot(res$transect_lines |> sf::st_geometry(), add = TRUE, col = 2, lwd = 0.5)  # }"},{"path":"/reference/data_input.html","id":null,"dir":"Reference","previous_headings":"","what":"Read SAV data from different formats — read_sav","title":"Read SAV data from different formats — read_sav","text":"Read SAV data different formats Read CSV file convert sf object Read spatial points file convert sf object Read spatial polygon file generate grid points","code":""},{"path":"/reference/data_input.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read SAV data from different formats — read_sav","text":"","code":"read_sav(   file_path,   spacing = 500,   layer = NULL,   crs = 32617,   crs_input = 4326,   export = NULL )  read_sav_csv(file_path, crs = 32617, crs_input = 4326, ...)  read_sav_pts(file_path, crs = 32617)  read_sav_aoi(file_path, spacing = 500, crs = 32617)"},{"path":"/reference/data_input.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read SAV data from different formats — read_sav","text":"file_path character Path spatial polygon file. spacing numeric Distance points meters. layer character Layer name multi-layer spatial files (default: NULL). crs object Coordinate reference system (CRS) output data (see sf::st_crs()). Default 32617. crs_input numeric Coordinate Reference System (CRS) input data, used CSV import. Default 4326. export character Optional. Folder path export outputs .gpkg. ... arguments passed utils::read.csv().","code":""},{"path":"/reference/data_input.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read SAV data from different formats — read_sav","text":"list points (sf object) polygon (sf object). sf object required optional columns. sf sf object required optional columns. list original polygon grid points.","code":""},{"path":"/reference/data_input.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read SAV data from different formats — read_sav","text":"","code":"# Example usage with CSV file library(sf) #> Linking to GEOS 3.12.1, GDAL 3.8.4, PROJ 9.4.0; sf_use_s2() is TRUE temp_csv <- tempfile(fileext = \".csv\") write.csv(data.frame(     longitude = c(-82.5, -83.0, -84.8),     latitude = c(42.5, 42.8, 42.6),     depth_m = c(5, 10, 7),     fetch_km = c(2.5, 3.0, 2.8),     secchi = c(1.2, 2.3, 1.8),     substrate = c(TRUE, FALSE, TRUE) ), temp_csv, row.names = FALSE)  tmp <- read_sav(temp_csv, crs = 32617, crs_input = 4326) #> ℹ Determining file type and processing: /tmp/RtmpGS0bL9/file21672a255e5a.csv #> ℹ csv detected #> ℹ Retained columns: longitude, latitude, depth_m, fetch_km, secchi, substrate. #> Removed columns: None #> ℹ Transforming spatial data. head(tmp$points) #> Simple feature collection with 3 features and 6 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 188247.3 ymin: 4706383 xmax: 376749.5 ymax: 4740545 #> Projected CRS: WGS 84 / UTM zone 17N #>   longitude latitude depth_m fetch_km secchi substrate                 geometry #> 1  376749.5  4706383       5      2.5    1.2      TRUE POINT (376749.5 4706383) #> 2  336453.0  4740545      10      3.0    2.3     FALSE   POINT (336453 4740545) #> 3  188247.3  4723400       7      2.8    1.8      TRUE POINT (188247.3 4723400) plot(st_geometry(tmp$polygon)) plot(st_geometry(tmp$points), add = TRUE)   # Example usage with spatial polygon file (AOI) temp_poly <- st_sf(     geometry = st_sfc(st_polygon(list(         rbind(             c(-82.5, 42.5), c(-82.5, 42.8), c(-82.0, 42.8), c(-82.0, 42.5), c(-82.5, 42.5)         )     )), crs = 4326) ) temp_file <- tempfile(fileext = \".gpkg\") st_write(temp_poly, temp_file, quiet = TRUE)  tmp <- read_sav(temp_file, spacing = 500, crs = 32617) #> ℹ Determining file type and processing: /tmp/RtmpGS0bL9/file21675e4a5f55.gpkg #> ℹ spatial file detected #> ℹ Transforming spatial data. #> ✔ Grid of 5470 points successfully generated from AOI. head(tmp$points) #> Simple feature collection with 6 features and 2 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 400999.5 ymin: 4706028 xmax: 403499.5 ymax: 4706028 #> Projected CRS: WGS 84 / UTM zone 17N #>                   geometry longitude latitude #> 1 POINT (400999.5 4706028)  400999.5  4706028 #> 2 POINT (401499.5 4706028)  401499.5  4706028 #> 3 POINT (401999.5 4706028)  401999.5  4706028 #> 4 POINT (402499.5 4706028)  402499.5  4706028 #> 5 POINT (402999.5 4706028)  402999.5  4706028 #> 6 POINT (403499.5 4706028)  403499.5  4706028 plot(st_geometry(tmp$polygon)) plot(st_geometry(tmp$points), add = TRUE)   # Example CSV file creation temp_csv <- tempfile(fileext = \".csv\") write.csv(data.frame(     longitude = c(-82.5, -83.0, -83.2),     latitude = c(42.5, 42.8, 42.6),     depth_m = c(5, 10, 7),     fetch_km = c(2.5, 3.0, 2.8),     secchi = c(1.2, 2.3, 1.8),     substrate = c(TRUE, FALSE, TRUE),     limitation = c(FALSE, FALSE, TRUE) ), temp_csv, row.names = FALSE)  # Read the CSV and convert to sf read_sav_csv(temp_csv, crs = 32614, crs_input = 4326) #> ℹ Retained columns: longitude, latitude, depth_m, fetch_km, secchi, substrate, limitation. #> Removed columns: None #> ℹ Transforming spatial data. #> Simple feature collection with 3 features and 7 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 1797381 ymin: 4839111 xmax: 1857187 ymax: 4864546 #> Projected CRS: WGS 84 / UTM zone 14N #>   longitude latitude depth_m fetch_km secchi substrate limitation #> 1   1857187  4839264       5      2.5    1.2      TRUE      FALSE #> 2   1809500  4864546      10      3.0    2.3     FALSE      FALSE #> 3   1797381  4839111       7      2.8    1.8      TRUE       TRUE #>                  geometry #> 1 POINT (1857187 4839264) #> 2 POINT (1809500 4864546) #> 3 POINT (1797381 4839111) # Example spatial points file creation (requires sf package) library(sf) temp_sf <- st_sf(     longitude = c(-82.5, -83.0),     latitude = c(42.5, 42.8),     depth_m = c(5, 10),     geometry = st_sfc(         st_point(c(-82.5, 42.5)),         st_point(c(-83.0, 42.8))     ),     crs = 4326 )  temp_file <- tempfile(fileext = \".gpkg\") st_write(temp_sf, temp_file, quiet = TRUE)  # Read the spatial file and convert to sf read_sav_pts(temp_file) #> ℹ Transforming spatial data. #> ℹ Retained columns: longitude, latitude, depth_m. #> Removed columns: None #> ✔ Spatial points file successfully read and processed. #> Simple feature collection with 2 features and 3 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 336453 ymin: 4706383 xmax: 376749.5 ymax: 4740545 #> Projected CRS: WGS 84 / UTM zone 17N #>   longitude latitude depth_m                     geom #> 1  376749.5  4706383       5 POINT (376749.5 4706383) #> 2  336453.0  4740545      10   POINT (336453 4740545)  # Example spatial polygon file creation (requires sf package) library(sf) temp_poly <- st_sf(     geometry = st_sfc(st_polygon(list(         rbind(             c(-82.5, 42.5), c(-82.5, 42.8), c(-82.0, 42.8), c(-82.0, 42.5), c(-82.5, 42.5)         )     )), crs = 4326) ) temp_file <- tempfile(fileext = \".gpkg\") st_write(temp_poly, temp_file, quiet = TRUE)  # Read the spatial polygon file and generate a grid read_sav_aoi(temp_file, spacing = 500) #> ℹ Transforming spatial data. #> ✔ Grid of 5470 points successfully generated from AOI. #> $polygon #> Simple feature collection with 1 feature and 0 fields #> Geometry type: POLYGON #> Dimension:     XY #> Bounding box:  xmin: 376749.5 ymin: 4705778 xmax: 418227.5 ymax: 4739697 #> Projected CRS: WGS 84 / UTM zone 17N #>                             geom #> 1 POLYGON ((376749.5 4706383,... #>  #> $points #> Simple feature collection with 5470 features and 2 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 376999.5 ymin: 4706028 xmax: 417999.5 ymax: 4739528 #> Projected CRS: WGS 84 / UTM zone 17N #> First 10 features: #>                    geometry longitude latitude #> 1  POINT (400999.5 4706028)  400999.5  4706028 #> 2  POINT (401499.5 4706028)  401499.5  4706028 #> 3  POINT (401999.5 4706028)  401999.5  4706028 #> 4  POINT (402499.5 4706028)  402499.5  4706028 #> 5  POINT (402999.5 4706028)  402999.5  4706028 #> 6  POINT (403499.5 4706028)  403499.5  4706028 #> 7  POINT (403999.5 4706028)  403999.5  4706028 #> 8  POINT (404499.5 4706028)  404499.5  4706028 #> 9  POINT (404999.5 4706028)  404999.5  4706028 #> 10 POINT (405499.5 4706028)  405499.5  4706028 #>"},{"path":"/reference/invert_polygon.html","id":null,"dir":"Reference","previous_headings":"","what":"Invert a Polygon — invert_polygon","title":"Invert a Polygon — invert_polygon","text":"Invert Polygon","code":""},{"path":"/reference/invert_polygon.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Invert a Polygon — invert_polygon","text":"","code":"invert_polygon(polygon, ratio = 0.5)"},{"path":"/reference/invert_polygon.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Invert a Polygon — invert_polygon","text":"polygon sf Polygon defining land boundaries needs inverted. ratio numeric [0-1] Fraction convex, see sf::st_concave_hull(). may need tweaked depending form polygon inverted.","code":""},{"path":"/reference/invert_polygon.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Invert a Polygon — invert_polygon","text":"Utility function inverts polygon drawing concave hull around polygon (see sf::st_concave_hull()) computes differences polygon concave hull (see sf::st_concave_hull()).","code":""},{"path":"/reference/invert_polygon.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Invert a Polygon — invert_polygon","text":"","code":"# \\donttest{ erie_land <- system.file(  \"example\", \"lake_erie_land\", \"LkErie_Land_fromGLAF_Water_WGS_Feb2020.shx\",   package = \"SAVM\", mustWork = TRUE ) |> sf::st_read() #> Reading layer `LkErie_Land_fromGLAF_Water_WGS_Feb2020' from data source  #>   `/home/runner/work/_temp/Library/SAVM/example/lake_erie_land/LkErie_Land_fromGLAF_Water_WGS_Feb2020.shx'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 1 feature and 8 fields #> Geometry type: MULTIPOLYGON #> Dimension:     XYZ #> Bounding box:  xmin: -83.58067 ymin: 41.30372 xmax: -78.72656 ymax: 42.99789 #> z_range:       zmin: 0 zmax: 0 #> Geodetic CRS:  WGS 84  erie_land |>    sf::st_geometry() |>    plot(col = 1)   erie_land |>    sf::st_geometry() |>    invert_polygon() |>    plot(col = 1) #> although coordinates are longitude/latitude, st_difference assumes that they #> are planar  # }"},{"path":"/reference/plot_sav.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot SAV Data Distribution — plot_sav_distribution","title":"Plot SAV Data Distribution — plot_sav_distribution","text":"function generates four plots representing distribution submerged aquatic vegetation (SAV) data depth (m) fetch (km). visualizes SAV presence/absence (PA) percent cover (Cover) corresponding columns available input data. function generates one two density plots submerged aquatic vegetation (SAV) presence (green) absence (blue) function depth (m) /fetch (km). includes vertical dotted lines indicating mean values . function generates interactive static map submerged aquatic vegetation (SAV) data, visualizing cover, presence/absence, depth, fetch values.","code":""},{"path":"/reference/plot_sav.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot SAV Data Distribution — plot_sav_distribution","text":"","code":"plot_sav_distribution(   dat,   type = c(\"pa\", \"cover\"),   predictors = c(\"depth\", \"fetch\"),   post_hoc = TRUE,   max_depth = 30,   max_fetch = 15 )  plot_sav_density(   dat,   predictors = c(\"depth\", \"fetch\"),   max_depth = 30,   post_hoc = TRUE )  plot_sav_tmap(   study_zone,   layers = c(\"pa\", \"cover\", \"depth\", \"fetch\"),   interactive = TRUE,   export_path = NULL,   post_hoc = TRUE )"},{"path":"/reference/plot_sav.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot SAV Data Distribution — plot_sav_distribution","text":"dat data.frame containing: depth_m (optional): Numeric, depth meters. fetch_km (optional): Numeric, fetch kilometers. pa: Binary (0 = absent, 1 = present), indicating SAV presence/absence. type character vector Character vector specifying type plots generate. Options: \"pa\" (default) presence/absence plots \"cover\" (default) cover percentage plots predictors Character vector specifying predictors use. Options: \"depth\" (default) depth-based plots \"fetch\" (default) fetch-based plots post_hoc Logical value indicating whether use post-hoc analyzed columns (pa_post_hoc, cover_post_hoc) instead raw columns (pa, cover). Default FALSE. max_depth Numeric value specifying maximum depth bin (default: 30 meters). max_fetch numeric Numeric value specifying maximum fetch bin (default: 15 km). study_zone list containing spatial objects: polygon: sf polygon object representing area interest. points: sf points object containing SAV-related attributes. layers Character vector specifying layers generate. Options: \"pa\" (default) presence/absence model predictions \"cover\" (default) cover percentage model predictions \"depth\" (default) depth predictor values \"fetch\" (default) fetch predictor values interactive Logical. TRUE (default), generates interactive map. FALSE, creates static map. export_path Character. provided, saves map specified file path. Default NULL.","code":""},{"path":"/reference/plot_sav.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot SAV Data Distribution — plot_sav_distribution","text":"set ggplot2 plots displayed grid layout. One two ggplot2 density plots visualizing SAV presence/absence depth /fetch. tmap map object, optionally saved file.","code":""},{"path":"/reference/plot_sav.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot SAV Data Distribution — plot_sav_distribution","text":"","code":"# Example dataset dat <- data.frame(     depth_m = runif(100, 0, 15),     fetch_km = runif(100, 0, 15),     pa_pred = sample(0:1, 100, replace = TRUE),     cover_pred = runif(100, 0, 100),     pa_post_hoc = sample(0:1, 100, replace = TRUE),     cover_post_hoc = runif(100, 0, 100) )  # Generate all available plots plot_sav_distribution(dat)   # Generate only presence/absence plots plot_sav_distribution(dat, type = \"pa\")   # Generate cover plots using only fetch as predictor plot_sav_distribution(dat, type = \"cover\", predictors = \"fetch\")   # Generate plots using post-hoc analyzed data plot_sav_distribution(dat, post_hoc = TRUE)   # Example dataset dat <- data.frame(     depth_m = runif(100, 0, 15),     fetch_km = runif(100, 0, 15),     pa_pred = sample(0:1, 100, replace = TRUE),     pa_post_hoc = sample(0:1, 100, replace = TRUE) )  # Generate all available plots plot_sav_density(dat)   # Generate depth-based density plot only plot_sav_density(dat, predictors = \"depth\")   # Generate fetch-based density plot only plot_sav_density(dat, predictors = \"fetch\")   # Generate plots using post-hoc analyzed data plot_sav_density(dat, post_hoc = TRUE)  polygon <- system.file(\"example\", \"lake_erie.gpkg\", package = \"SAVM\") |>     sf::st_read() |>     sf::st_simplify(dTolerance = 1000) #> Reading layer `lake_erie' from data source  #>   `/home/runner/work/_temp/Library/SAVM/example/lake_erie.gpkg'  #>   using driver `GPKG' #> Simple feature collection with 1 feature and 1 field #> Geometry type: MULTIPOLYGON #> Dimension:     XYZ #> Bounding box:  xmin: -83.47975 ymin: 41.38081 xmax: -78.85269 ymax: 42.94512 #> z_range:       zmin: 0 zmax: 0 #> Geodetic CRS:  WGS 84 #> st_as_s2(): dropping Z and/or M coordinate  # Create sample points with attributes set.seed(42) points <- sf::st_sample(polygon, 100) |>     sf::st_sf() |>     dplyr::mutate(         cover_pred = runif(100, 0, 100),         pa_pred = sample(0:1, 100, replace = TRUE) |>             factor(levels = c(0, 1), labels = c(\"Absent\", \"Present\")),         depth_m = runif(100, 0, 15),         fetch_km = runif(100, 0, 10),         cover_post_hoc = runif(100, 0, 100),         pa_post_hoc = sample(0:1, 100, replace = TRUE) |>             factor(levels = c(0, 1), labels = c(\"Absent\", \"Present\")),     )  # Combine into study_zone list study_zone <- list(polygon = polygon, points = points)  # Generate an interactive map plot_sav_tmap(study_zone, interactive = TRUE)  # Generate a static map plot_sav_tmap(study_zone, layers = \"cover\", interactive = FALSE)   # Save map to html file if (FALSE) { # \\dontrun{ plot_sav_tmap(study_zone, export_path = \"sav_map.html\") } # }  # Visualize interactive map & save map to static png file if (FALSE) { # \\dontrun{ plot_sav_tmap(study_zone, layers = \"pa\", export_path = \"sav_map.png\") } # }"},{"path":"/reference/preview_grid.html","id":null,"dir":"Reference","previous_headings":"","what":"Preview grid — preview_grid","title":"Preview grid — preview_grid","text":"Preview grid","code":""},{"path":"/reference/preview_grid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preview grid — preview_grid","text":"","code":"preview_grid(x)  # S3 method for class 'sav_data' preview_grid(x)"},{"path":"/reference/preview_grid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preview grid — preview_grid","text":"x object class sav_data.","code":""},{"path":"/reference/preview_grid.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Preview grid — preview_grid","text":"preview_grid(sav_data): Preview spatail grid.","code":""},{"path":"/reference/sav_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply Random Forest models — sav_model","title":"Apply Random Forest models — sav_model","text":"Apply Random Forest models predict SAV cover presence/absence, optional post-hoc processing.","code":""},{"path":"/reference/sav_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply Random Forest models — sav_model","text":"","code":"sav_model(   dat,   type = c(\"cover\", \"pa\"),   depth = NULL,   fetch = NULL,   substrate = NULL,   secchi = NULL,   limitation = NULL,   vmax_par = list(intercept = 1.4, slope = 1.33) )"},{"path":"/reference/sav_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply Random Forest models — sav_model","text":"dat data.frame|sf data.frame sf object containing following columns: depth_m: Numeric, depth meters. fetch_km: Numeric, fetch kilometers. secchi: Numeric Secchi depth meters (post_hoc) substrate: Binary (0 = absent, 1 = present), indicating substrate limitations. (post_hoc) limitation: Binary (0 = absent, 1 = present), indicating user-supplied limitations. Additional columns ignored. type character vector, either \"cover\" \"pa\" Model type(s). depth, fetch character Column specification predictors, see Details. substrate, secchi, limitation characterColumn specification post_hoc variables, see Details. vmax_par named list intercept slope equation Chambers Kalff (1985) compute maximum depth plant colonization (Vmax), see Details .","code":""},{"path":"/reference/sav_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply Random Forest models — sav_model","text":"data frame (sf object) containing input columns along model predictions. prediction column names match values specified type followed suffix _pred, contain raw model outputs (.e., without post-hoc adjustment). Post-hoc adjusted predictions (see Details) included additional columns names type values, suffix _post_hoc. column secchi present, two additional columns returned: vmax limitation_secchi, see details explanation.","code":""},{"path":"/reference/sav_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Apply Random Forest models — sav_model","text":"two sets models available. first set consists models predicting presence absence SAV, second set focuses SAV cover. set includes three random forest models: one using depth predictor, another using fetch, third combining variables. details, see Croft-White (2022). selected model generating predictions determined type argument, specifies output either cover presence-absence, depending available predictors. required input variables—depth, fetch, substrate, secchi, limitation—must correspond column names dat; otherwise, error thrown. neither 'depth' 'fetch' explicitly provided, function attempt infer column names. Matching case-insensitive detect 'depth_m', 'depth', 'fetch_km' 'fetch'. secchi provided, two additional columns returned: vmax: Predicted maximum colonization depth calculated using Chambers Kalff equation. limitation_secchi: Logical column indicating light limitation. TRUE vmax >= depth_m,  indicating site light-limited; FALSE otherwise. regression parameters Chambers Kalff equation can adjusted via vmax_par argument. default, parameters Model (Quebec international lakes) Croft-White et al. (2022) used. apply Model B (Quebec lakes ), use: vmax_par = list(intercept = 1.32, slope = 1.14) post-hoc treatment adjusts raw predictions setting 0 wherever limitations present. Possible limitation columns include substrate, limitation, limitation_secchi (see descriptions ). columns treated binary indicators: value greater 0 interpreted limiting condition. limitation detected, corresponding prediction set 0 post-hoc adjusted output.","code":""},{"path":"/reference/sav_model.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Apply Random Forest models — sav_model","text":"Croft-White, M.V., Tang, R., Gardner Costa, J., Doka, S.E., Midwood, J. D. 2022. Modelling submerged aquatic vegetation presence percent cover support development freshwater fish habitat management tool. Can. Tech. Rep. Fish. Aquat. Sci. 3497: vi + 30 p. Chambers, P.., Kalff, J. 1985. Depth Distribution Biomass Submerged aquatic macrophyte communities relation secchi depth. Can. J. Fish. Aquat. Sci. 42: 701–709","code":""},{"path":"/reference/sav_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply Random Forest models — sav_model","text":"","code":"# \\donttest{  # basic usage  sav_model(data.frame(depth = c(5, 10))) #> ℹ Looking for depth and fetch in column names. #> ℹ Found Depth in column names. #> ℹ Using cover and pa with depth #>   depth_m pa_pred cover_pred pa_post_hoc cover_post_hoc #> 1       5       1   85.43167           1       85.43167 #> 2      10       0   21.14400           0        0.00000 sav_model(data.frame(depth = c(5, 10), fetch = c(1, 2)), type = \"pa\") #> ℹ Looking for depth and fetch in column names. #> ℹ Found Fetch and Depth in column names. #> ℹ Using pa with depth+fetch #>   depth_m fetch_km pa_pred pa_post_hoc #> 1       5        1       0           0 #> 2      10        2       0           0  # using post-hoc treatment  sav_model(  data.frame(   depth = c(5, 10, 5),    fetch = c(1, 2, 10),    secchi = c(1, 10, 10),    substrate = c(TRUE, TRUE, FALSE)  ) ) #> ℹ Looking for depth and fetch in column names. #> ℹ Found Fetch and Depth in column names. #> ℹ Using cover and pa with depth+fetch #>   depth_m fetch_km secchi limitation_secchi     vmax substrate pa_pred #> 1       5        1      1             FALSE  1.76890      TRUE       0 #> 2      10        2     10              TRUE 19.29351      TRUE       0 #> 3       5       10     10              TRUE 19.29351     FALSE       1 #>   cover_pred pa_post_hoc cover_post_hoc #> 1   77.11233           0              0 #> 2   44.66533           0              0 #> 3   60.24833           0              0 # }"}]
